defaults:
  - model: conformer
  - metrics: wer_cer
  - writer: wandb
  - datasets: librispeech_test # we do not want to run inference on training data
  - dataloader: base
  - transforms: spec_aug_gain
  - _self_
text_encoder:
  _target_: src.text_encoder.CTCTextEncoder
  use_bpe: True
inferencer:
  device_tensors: ["spectrogram", "text_encoded"] # which tensors should be on device (ex. GPU)
  device: auto # device name or "auto"
  save_path: null
  seed: 42
  from_pretrained: "data/models/best_ctc_conformer.pth" # path to the pretrained model
